{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielaburaglia/Documents/GitHub/AI4DM_lab/.venvAI4DMLab/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2text(imgUrl):\n",
    "\n",
    "    lab_pipe = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-large\")\n",
    "    text = lab_pipe(imgUrl)[0][\"generated_text\"]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielaburaglia/Documents/GitHub/AI4DM_lab/.venvAI4DMLab/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "/Users/gabrielaburaglia/Documents/GitHub/AI4DM_lab/.venvAI4DMLab/lib/python3.12/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a woman and man sitting in a chair looking at a tablet\n"
     ]
    }
   ],
   "source": [
    "scenario = img2text(\"static/imgs/networking.png\")\n",
    "#print(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textGeneration(msg):\n",
    "    client = OpenAI()\n",
    "    msg_list = [{\"role\": \"system\", \"content\": \"You are an expert short story teller. Using a simple narrative you generate story in less than 100 words based on the given scenario. \"}]\n",
    "    msg_list. append(msg)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model= \"gpt-4o-mini\", #\"gpt-4o\"\n",
    "        temperature=0.2,\n",
    "        max_completion_tokens = 200, \n",
    "        messages = msg_list\n",
    "    )\n",
    "    out_message = response.choices[0].message.content\n",
    "    return(out_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='In a cozy corner of a bustling café, Sarah and Tom huddled together, their eyes glued to the tablet. Laughter erupted as they scrolled through old photos, reliving memories of their spontaneous road trip. Each image sparked a story, a shared secret, a moment frozen in time. As the sun dipped below the horizon, casting a warm glow, Tom leaned closer, whispering, “Let’s make more memories.” Sarah smiled, her heart fluttering. With a simple tap, they booked their next adventure, ready to fill their lives with laughter and love, one photo at a time.', refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "msg = {\"role\": \"user\", \"content\": scenario}\n",
    "story = textGeneration(msg)\n",
    "print(story)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvAI4DMLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
