{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader #load the document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter #for creating chunks from the loaded document\n",
    "from langchain_openai import OpenAIEmbeddings #for converting chunks into embeddings\n",
    "from langchain_chroma import Chroma #database for stroring the embeddings\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 36 0 (offset 0)\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n",
      "Ignoring wrong pointing object 40 0 (offset 0)\n",
      "Ignoring wrong pointing object 87 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"/Users/gabrielaburaglia/Desktop/guide.pdf\")\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document chunk info:\n",
      "\n",
      "Number of document chunks: 21\n",
      "Sample chunk: \n",
      "Secret book safe  You need: Ø A hardcover book Ø Carpet cutter  Time: ca. 30 min, depending on the size of the book Instructions: Fairly easy: Open the book and draw a rectangle on the first page. It should be the size of the secret compartment you want to create (it’s easiest to just cut out all the text body). Cut this rectangle out of all pages but make sure you don’t cut outside the rectangle. In the end, all pages should form a frame for an empty space in the middle (like a very thick empty picture frame). So from outside, it still looks like a book… but who knows what you hide in your bookshelf? You can also cut out multiple smaller compartments and make it a jewelry box. Let the google picture search “secret book box upcycling” inspire you!  \n",
      " https://www.ehow.com/way_5697122_easy-crafts-using-household-items.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Split the document into chunks using text splitters \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(document)\n",
    "\n",
    "print(\"Document chunk info:\\n\")\n",
    "print(f\"Number of document chunks: {len(chunks)}\")\n",
    "print(f\"Sample chunk: \\n{chunks[12].page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create embeddings using openAI embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gabrielaburaglia/Documents/GitHub/reuse_buddy_M2/chroma_db\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "  \n",
    "db_dir = os.path.join(cwd,\"chroma_db\")\n",
    "print(db_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x154e74650>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store the embeddings and chunks into Chroma DB\n",
    "Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the DB for retrieval\n",
    "embeddings_used = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorDB = Chroma(persist_directory=db_dir,embedding_function=embeddings_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up Retriver\n",
    "retriever = vectorDB.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRetriever(dir):\n",
    "    \"\"\"\n",
    "    dir is the directory of the vector DB\n",
    "    \"\"\"\n",
    "    embeddings_used = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorDB = Chroma(persist_directory=dir,embedding_function=embeddings_used)\n",
    "    retriever = vectorDB.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def societal_definition(type):\n",
    "    society_dict = {\n",
    "        \"Growing\": \"Focused on expansion, development, and continued acceleration.\",\n",
    "        \"Collapsing\": \"Focused on the decline or breakdown of society, leading to a simpler society.\",\n",
    "        \"Controlling\": \"Focused on managing and controlling societal excesses to preserve resources and maintain order, guided by various values and authoritarian control.\",\n",
    "        \"Transforming\": \"Focused on embracing radical changes that reshapes humanity and the environment, leading to a posthuman future.\"\n",
    "    }\n",
    "    return society_dict.get(type,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textGeneration_langChain_RAG(msg,type, retrieverDir):\n",
    "    \"\"\"\n",
    "    msg is the scenario for the story from the pic (hugging face model output);\n",
    "    type is the sustainability suggestion mode - Growing, Collapsing, Controlling, Transforming\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.2,\n",
    "        max_tokens=200,\n",
    "        timeout=None,\n",
    "        max_retries=2\n",
    "    )\n",
    "\n",
    "    defintion = societal_definition(type)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are an advocate of sustainability. With the object given, come up with a way to reuse this object in the future. From the viewpoint of a society that is {suggestion_mode}. A {suggestion_mode} society is defined as one that is: {societal_definition}.\"\n",
    "        \"Use the following pieces of retrieved context to generate sustainable, upcycled, object reuse ideas. \"\n",
    "        \"Keep the idea to less than 200 words.\"\n",
    "        \"\\n\\n\"\n",
    "        \"{context}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\", \n",
    "                system_prompt\n",
    "            ),\n",
    "            (\n",
    "                \"human\", \n",
    "                \"{scenario_lang}\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    retriever = getRetriever(retrieverDir)\n",
    "\n",
    "    out_message = rag_chain.invoke({\n",
    "            \"context\":retriever,\n",
    "            \"suggestion_mode\" : type,\n",
    "            \"scenario_lang\" : msg,\n",
    "            \"societal_definition\": defintion,\n",
    "        })\n",
    "\n",
    "    return out_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a collapsing society where resources are scarce and innovation is key to survival, a garden hose can be repurposed in several sustainable ways. First, it can be transformed into a drip irrigation system for small-scale agriculture. By puncturing small holes along the length of the hose and laying it alongside crops, it can efficiently deliver water directly to the roots, conserving water and maximizing crop yield.\n",
      "\n",
      "Additionally, sections of the hose can be used as durable ties or bindings. They can secure structures, bind bundles of firewood, or even serve as makeshift belts or straps. The flexibility and strength of the hose material make it ideal for these purposes.\n",
      "\n",
      "Furthermore, garden hoses can be cut into smaller pieces to create protective grips for tools or handles, providing comfort and reducing wear on hands during manual labor. Lastly, they can be used as insulation for pipes or as padding to prevent damage to fragile items during transport.\n",
      "\n",
      "By creatively reimagining the use of a garden hose, communities can enhance their resilience and resource\n"
     ]
    }
   ],
   "source": [
    "scenario = \"garden hose\" #example output from huggingface model\n",
    "story = textGeneration_langChain_RAG(scenario,\"Collapsing\", db_dir)\n",
    "print(story)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
